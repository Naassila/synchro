{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import datagenerators as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal inference\n",
    "# Part 1 : using the potential outcomes framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give an overview of how we can use the [potential outcomes](https://en.wikipedia.org/wiki/Rubin_causal_model) framework to try and make causal inferences about situations where we only have observational data.\n",
    "\n",
    "We will use generated data. These data are independent and identically distributed random variables from some distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: wearing cool hats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manager notices that some membres of their team wear cool hats, and that these members tend to be less productive.\n",
    "\n",
    "- hat: $X=1$ for a cool hat; $X=0$ for no cool hat\n",
    "- productivity: $Y=1$ for productive; $Y=0$ for unproductive\n",
    "\n",
    "After a week, they end up with the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  0\n",
       "1  1  0\n",
       "2  0  1\n",
       "3  0  1\n",
       "4  1  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_data_0 = dg.generate_dataset_0()\n",
    "print(observed_data_0.shape)\n",
    "observed_data_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are people wearing cool hats more likely to be productive that those who don't?\n",
    "This is the first question the team lead asks.\n",
    "This means estimating the quantity: \n",
    "\n",
    "$$P(Y=1|X=1) - (Y=1|X=0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimated_effect': -0.16374269005847958,\n",
       " 'standard_error': 0.08661600610290666}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_uplift(ds):\n",
    "    \"\"\"\n",
    "    Estimate the difference in means between two groups.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: pandas.DataFrame\n",
    "        a dataframe of samples.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    estimated_uplift: dict[Str: float] containing two items:\n",
    "        \"estimated_effect\" - the difference in mean values of $y$ for treated and untreated samples.\n",
    "        \"standard_error\" - 90% confidence intervals arround \"estimated_effect\"   \n",
    "    \"\"\"\n",
    "    base = ds[ds.x == 0]\n",
    "    variant = ds[ds.x == 1]\n",
    "\n",
    "    delta = variant.y.mean() - base.y.mean()\n",
    "    delta_err = 1.96 * np.sqrt(variant.y.var() / variant.shape[0] +\n",
    "                               base.y.var() / base.shape[0])\n",
    "\n",
    "    return {\"estimated_effect\": delta, \"standard_error\": delta_err}\n",
    "\n",
    "\n",
    "estimate_uplift(observed_data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like people with cool hats are less productive.\n",
    "\n",
    "To be sure, we can even run a statistical test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00034699294835294664"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = observed_data_0.assign(placeholder=1).pivot_table(\n",
    "    index=\"x\", columns=\"y\", values=\"placeholder\", aggfunc=\"sum\")\n",
    "\n",
    "_, p, _, _ = chi2_contingency(contingency_table, lambda_=\"log-likelihood\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's one small p-value. [Staticians would be proud](https://www.nature.com/articles/s41562-017-0189-z).\n",
    "\n",
    "We can use this information to make statements about what we might think about someone's probability if we see them wearing a cool hat. As long as we believe that they are \"drawn from the same distribution\" as our previous observations, we expect the same correlations to exist.\n",
    "\n",
    "The problem comes if we try to use this information as an argument about whether or not the team lead should **force** people to wear cool hats. If the team lead does this they fundamentally change the system we are sampling from, potentially altering or even reversing any correlations we observed before.\n",
    "\n",
    "The cleanest way to actually measure the effect of some change in a system is by running a __randomized control trial__. \n",
    "\n",
    "Specifically, we want to randomize who gets cool hats and who doesn't, and look at the different values of $y$ we receive. This removes the effect of any [confounding variables](https://en.wikipedia.org/wiki/Confounding) which might be influencing the metric we care about.\n",
    "\n",
    "Because we generated our dataset from a known process (in this case a function I wrote), we can intervene in it directly and measure the effect of an A/B test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimated_effect': 0.20140000000000002,\n",
       " 'standard_error': 0.019200006338266608}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_ab_test(datagenerator, n_samples=10000, filter_=None):\n",
    "    \"\"\"\n",
    "    Generates n_samples from datagenerator with the value of X randomized\n",
    "    so that 50% of the samples receive treatment X=1 and 50% receive X=0,\n",
    "    and feeds the results into `estimate_uplift` to get an unbiased \n",
    "    estimate of the average treatment effect.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    effect: dict\n",
    "    \"\"\"\n",
    "    n_samples_a = int(n_samples / 2)\n",
    "    n_samples_b = n_samples - n_samples_a\n",
    "    set_X = np.concatenate([np.ones(n_samples_a),\n",
    "                            np.zeros(n_samples_b)]).astype(np.int64)\n",
    "    ds = datagenerator(n_samples=n_samples, set_X=set_X)\n",
    "    if filter_ != None:\n",
    "        ds = ds[filter_(ds)].copy()\n",
    "    return estimate_uplift(ds)\n",
    "\n",
    "run_ab_test(dg.generate_dataset_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait. The direction of the effect has reversed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions of causality\n",
    "\n",
    "The previous example demonstrates the old statistics saying:\n",
    "\n",
    "> Correlation does not imply causation.\n",
    "\n",
    "In this notebook, causality mean \"**What is the effect of $Y$ of changing $X$**\".\n",
    "\n",
    "To be precise:\n",
    "- $X$ and $Y$ are random variables\n",
    "- the _effect_ we want to know is __how the distribution of $Y$ will change when we take a certain value of $X$__?\n",
    "- the act of forcing a variable to take a certain value is called an **intervention**\n",
    "\n",
    "- when we make no intervention, we have an observational distribution of $Y$, conditioned on the fact we observe $X$:\n",
    "$$P(Y|X)$$\n",
    "- when we force people to wear cool hats, we are making an _intervention_. The distribution of $Y$ is given by the intervention distribution:\n",
    "$$P(Y|\\text{do}(X))$$\n",
    "\n",
    "The question we will try to answer is how we can reason about the interventional distribution when we only have access to observational data.\n",
    "\n",
    "This is a useful question because there are lots of situations where running an A/B test to directly measure the effects of an intervention is impractical, unfeasable or unethical.\n",
    "\n",
    "In these situations we still want to be able to say something about what the effect of an intervention is - to do this we need to make some assumptions about the data generating process we are investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to approach this problem is to introduce two new random variables to our system: $Y_0$ and $Y_1$, known as the __potential outcomes__.\n",
    "These variables exist but are never directly observed.\n",
    "\n",
    "$Y$ is defined in terms of:\n",
    "\n",
    "- $Y = Y_1$ when $X = 1$\n",
    "- $Y = Y_0$ when $X = 0$\n",
    "\n",
    "This shifts the problem from one about how distributions change under the intervention, to one about data drawn i.i.d. from some underlying distribution with [missing values](https://en.wikipedia.org/wiki/Missing_data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Often, we do not care about the full intervention distribution $P(Y|\\text{do}(X))$, and it is enough to have an estimate of the difference in means.\n",
    "\n",
    "This is a quantity known as the Average Treatment Effect (ATE):\n",
    "\n",
    "$$\\Delta = E[Y_{1} - Y_{0}]$$\n",
    "\n",
    "When we run and A/B test and compare the means of each group, this is directly the quantity we are measuring.\n",
    "\n",
    "If we just try and estimate this quantity from the observational distribution, we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Delta_{bad} & = E[Y|X=1] - E[Y|X=0] \\\\\n",
    "& = E[Y_{1}|X=1] - E[Y_{0}|X=0] \\\\\n",
    "& \\neq \\Delta\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is not generally equal to the true ATE because:\n",
    "\n",
    "$E[Y_{i}|X=i] \\neq E[Y_{i}]$\n",
    "\n",
    "Two related quantities are \n",
    "\n",
    " - $ATT = E[Y_{1} - Y_{0}|X=1]$, the \"Average Treatment effect of the Treated\": measure of the effect of treating only samples which would naturally be treated\n",
    " - $ATC = E[Y_{1} - Y_{0}|X=0]$, the \"Average Treatment effect of the Control\": measure of the effect of treating only samples which wouldn't naturally be treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making assumptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synchro",
   "language": "python",
   "name": "synchro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
